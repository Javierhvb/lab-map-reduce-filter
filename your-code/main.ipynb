{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '../data/58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet = prophet[568:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the{7}', 'chosen', 'and', 'the\\nbeloved,', 'who', 'was', 'a', 'dawn', 'unto']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    return x.split(\"{\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_reference = list(map(reference,prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    return x.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_line = list(map(line_break, prophet_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_flat =  [y for x in prophet_line for y in x ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(x):    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    return x not in word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET',\n",
       " '',\n",
       " '|Almustafa,',\n",
       " 'chosen',\n",
       " 'beloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own',\n",
       " 'day,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'city',\n",
       " 'of',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to',\n",
       " 'return',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'isle',\n",
       " 'of',\n",
       " 'his',\n",
       " 'birth.',\n",
       " '',\n",
       " 'And',\n",
       " 'in',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'seventh',\n",
       " 'day',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he',\n",
       " 'climbed',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'city',\n",
       " 'walls',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'mist.',\n",
       " '',\n",
       " 'Then',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung',\n",
       " 'open,',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'sea.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'But',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'hill,',\n",
       " 'sadness',\n",
       " 'came',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart:',\n",
       " '',\n",
       " 'How',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'without',\n",
       " 'sorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'spirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " '',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'within',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'long',\n",
       " 'were',\n",
       " 'nights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart',\n",
       " 'from',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without',\n",
       " 'regret?',\n",
       " '',\n",
       " 'Too',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I',\n",
       " 'scattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'too',\n",
       " 'many',\n",
       " 'are',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk',\n",
       " 'naked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'withdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'burden',\n",
       " 'ache.',\n",
       " '',\n",
       " 'It',\n",
       " 'is',\n",
       " 'not',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this',\n",
       " 'day,',\n",
       " 'but',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own',\n",
       " 'hands.',\n",
       " '',\n",
       " 'Nor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,',\n",
       " 'but',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'with',\n",
       " 'thirst.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'Yet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.',\n",
       " '',\n",
       " 'The',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her',\n",
       " 'calls',\n",
       " 'me,',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.',\n",
       " '',\n",
       " 'For',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'crystallize',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'mould.',\n",
       " '',\n",
       " 'Fain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is',\n",
       " 'here.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?',\n",
       " '',\n",
       " 'A',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'tongue',\n",
       " '',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone',\n",
       " 'must',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'ether.',\n",
       " '',\n",
       " 'And',\n",
       " 'alone',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'eagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'sun.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'Now',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'hill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'sea,',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'harbour,',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'mariners,',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.',\n",
       " '',\n",
       " 'And',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'he',\n",
       " 'said:',\n",
       " '',\n",
       " 'Sons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of',\n",
       " 'tides,',\n",
       " '',\n",
       " 'How',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.',\n",
       " 'And',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.',\n",
       " '',\n",
       " 'Ready',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with',\n",
       " 'sails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'wind.',\n",
       " '',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in',\n",
       " 'this',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look',\n",
       " 'cast',\n",
       " 'backward,',\n",
       " '',\n",
       " 'And',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'seafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " '',\n",
       " 'you,',\n",
       " 'vast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,',\n",
       " '',\n",
       " 'Who',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'river',\n",
       " 'stream,',\n",
       " '',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream',\n",
       " 'make,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,',\n",
       " '',\n",
       " 'And',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'boundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'boundless',\n",
       " 'ocean.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " 'men',\n",
       " 'women',\n",
       " 'leaving',\n",
       " 'their',\n",
       " 'fields',\n",
       " 'their',\n",
       " 'vineyards',\n",
       " 'hastening',\n",
       " 'towards',\n",
       " 'city',\n",
       " 'gates.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'heard',\n",
       " 'their',\n",
       " 'voices',\n",
       " 'calling',\n",
       " 'his',\n",
       " 'name,',\n",
       " 'shouting',\n",
       " 'from',\n",
       " 'field',\n",
       " 'to',\n",
       " 'field',\n",
       " 'telling',\n",
       " 'one',\n",
       " 'another',\n",
       " 'of',\n",
       " 'coming',\n",
       " 'of',\n",
       " 'his',\n",
       " 'ship.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'said',\n",
       " 'to',\n",
       " 'himself:',\n",
       " '',\n",
       " 'Shall',\n",
       " 'day',\n",
       " 'of',\n",
       " 'parting',\n",
       " 'be',\n",
       " 'day',\n",
       " 'of',\n",
       " 'gathering?',\n",
       " '',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'it',\n",
       " 'be',\n",
       " 'said',\n",
       " 'that',\n",
       " 'my',\n",
       " 'eve',\n",
       " 'was',\n",
       " 'in',\n",
       " 'truth',\n",
       " 'my',\n",
       " 'dawn?',\n",
       " '',\n",
       " 'And',\n",
       " 'what',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'left',\n",
       " 'his',\n",
       " 'plough',\n",
       " 'in',\n",
       " 'midfurrow,',\n",
       " 'or',\n",
       " 'to',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'stopped',\n",
       " 'wheel',\n",
       " 'of',\n",
       " 'his',\n",
       " 'winepress?',\n",
       " '',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'become',\n",
       " 'tree',\n",
       " 'heavy-laden',\n",
       " 'with',\n",
       " 'fruit',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'gather',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'them?',\n",
       " '',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'my',\n",
       " 'desires',\n",
       " 'flow',\n",
       " 'like',\n",
       " 'fountain',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'fill',\n",
       " 'their',\n",
       " 'cups?',\n",
       " '',\n",
       " 'Am',\n",
       " 'I',\n",
       " 'harp',\n",
       " 'that',\n",
       " 'hand',\n",
       " 'of',\n",
       " 'mighty',\n",
       " 'may',\n",
       " 'touch',\n",
       " 'me,',\n",
       " 'or',\n",
       " 'flute',\n",
       " 'that',\n",
       " 'his',\n",
       " 'breath',\n",
       " 'may',\n",
       " 'pass',\n",
       " 'through',\n",
       " 'me?',\n",
       " '',\n",
       " 'A',\n",
       " 'seeker',\n",
       " 'of',\n",
       " 'silences',\n",
       " 'am',\n",
       " 'I,',\n",
       " 'what',\n",
       " 'treasure',\n",
       " 'have',\n",
       " 'I',\n",
       " 'found',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'dispense',\n",
       " 'with',\n",
       " 'confidence?',\n",
       " '',\n",
       " 'If',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'day',\n",
       " 'of',\n",
       " 'harvest,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'fields',\n",
       " 'have',\n",
       " 'I',\n",
       " 'sowed',\n",
       " 'seed,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'unremembered',\n",
       " 'seasons?',\n",
       " '',\n",
       " 'If',\n",
       " 'this',\n",
       " 'indeed',\n",
       " 'be',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'which',\n",
       " 'I',\n",
       " 'lift',\n",
       " 'up',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'my',\n",
       " 'flame',\n",
       " 'that',\n",
       " 'shall',\n",
       " 'burn',\n",
       " 'therein.',\n",
       " '',\n",
       " 'Empty',\n",
       " 'dark',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " '',\n",
       " 'And',\n",
       " 'guardian',\n",
       " 'of',\n",
       " 'night',\n",
       " 'shall',\n",
       " 'fill',\n",
       " 'it',\n",
       " 'with',\n",
       " 'oil',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'light',\n",
       " 'it',\n",
       " 'also.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'These',\n",
       " 'things',\n",
       " 'he',\n",
       " 'said',\n",
       " 'in',\n",
       " 'words.',\n",
       " 'But',\n",
       " 'much',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'remained',\n",
       " 'unsaid.',\n",
       " 'For',\n",
       " '',\n",
       " 'could',\n",
       " 'not',\n",
       " 'speak',\n",
       " 'his',\n",
       " 'deeper',\n",
       " 'secret.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " '[Illustration:',\n",
       " '0020]',\n",
       " '',\n",
       " 'And',\n",
       " 'when',\n",
       " 'he',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'city',\n",
       " 'all',\n",
       " 'people',\n",
       " 'came',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'him,',\n",
       " 'they',\n",
       " 'were',\n",
       " 'crying',\n",
       " 'out',\n",
       " 'to',\n",
       " 'him',\n",
       " 'as',\n",
       " 'with',\n",
       " 'one',\n",
       " 'voice.',\n",
       " '',\n",
       " 'And',\n",
       " 'elders',\n",
       " 'of',\n",
       " 'city',\n",
       " 'stood',\n",
       " 'forth',\n",
       " 'said:',\n",
       " '',\n",
       " 'Go',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'away',\n",
       " 'from',\n",
       " 'us.',\n",
       " '',\n",
       " 'A',\n",
       " 'noontide',\n",
       " 'have',\n",
       " 'you',\n",
       " 'been',\n",
       " 'in',\n",
       " 'our',\n",
       " 'twilight,',\n",
       " 'your',\n",
       " 'youth',\n",
       " 'has',\n",
       " 'given',\n",
       " 'us',\n",
       " 'dreams',\n",
       " 'to',\n",
       " 'dream.',\n",
       " '',\n",
       " 'No',\n",
       " 'stranger',\n",
       " 'are',\n",
       " 'you',\n",
       " 'among',\n",
       " 'us,',\n",
       " 'nor',\n",
       " 'guest,',\n",
       " 'but',\n",
       " 'our',\n",
       " 'son',\n",
       " 'our',\n",
       " 'dearly',\n",
       " 'beloved.',\n",
       " '',\n",
       " 'Suffer',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'our',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'hunger',\n",
       " 'for',\n",
       " 'your',\n",
       " 'face.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'priests',\n",
       " 'priestesses',\n",
       " 'said',\n",
       " 'unto',\n",
       " 'him:',\n",
       " '',\n",
       " 'Let',\n",
       " 'not',\n",
       " 'waves',\n",
       " 'of',\n",
       " 'sea',\n",
       " 'separate',\n",
       " 'us',\n",
       " 'now,',\n",
       " 'years',\n",
       " 'you',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'in',\n",
       " 'our',\n",
       " 'midst',\n",
       " 'become',\n",
       " 'memory.',\n",
       " '',\n",
       " 'You',\n",
       " 'have',\n",
       " 'walked',\n",
       " 'among',\n",
       " 'us',\n",
       " 'spirit,',\n",
       " '',\n",
       " 'your',\n",
       " 'shadow',\n",
       " 'has',\n",
       " 'been',\n",
       " 'light',\n",
       " 'upon',\n",
       " 'our',\n",
       " 'faces.',\n",
       " '',\n",
       " 'Much',\n",
       " 'have',\n",
       " 'we',\n",
       " 'loved',\n",
       " 'you.',\n",
       " 'But',\n",
       " 'speechless',\n",
       " 'was',\n",
       " 'our',\n",
       " 'love,',\n",
       " 'with',\n",
       " 'veils',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'veiled.',\n",
       " '',\n",
       " 'Yet',\n",
       " 'now',\n",
       " 'it',\n",
       " 'cries',\n",
       " 'aloud',\n",
       " 'unto',\n",
       " 'you,',\n",
       " 'would',\n",
       " 'stand',\n",
       " 'revealed',\n",
       " 'before',\n",
       " 'you.',\n",
       " '',\n",
       " 'And',\n",
       " 'ever',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'that',\n",
       " 'love',\n",
       " 'knows',\n",
       " 'not',\n",
       " 'its',\n",
       " 'own',\n",
       " 'depth',\n",
       " 'until',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'separation.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'others',\n",
       " 'came',\n",
       " 'also',\n",
       " 'entreated',\n",
       " 'him.',\n",
       " 'But',\n",
       " 'he',\n",
       " 'answered',\n",
       " 'them',\n",
       " 'not.',\n",
       " 'He',\n",
       " 'only',\n",
       " 'bent',\n",
       " 'his',\n",
       " 'head;',\n",
       " 'those',\n",
       " 'who',\n",
       " 'stood',\n",
       " 'near',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'tears',\n",
       " 'falling',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'breast.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'people',\n",
       " 'proceeded',\n",
       " 'towards',\n",
       " 'great',\n",
       " 'square',\n",
       " 'before',\n",
       " 'temple.',\n",
       " '',\n",
       " 'And',\n",
       " 'there',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sanctuary',\n",
       " 'woman',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'was',\n",
       " 'Almitra.',\n",
       " 'And',\n",
       " 'she',\n",
       " 'was',\n",
       " 'seeress.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'with',\n",
       " 'exceeding',\n",
       " 'tenderness,',\n",
       " 'for',\n",
       " 'it',\n",
       " 'was',\n",
       " 'she',\n",
       " 'who',\n",
       " 'had',\n",
       " 'first',\n",
       " 'sought',\n",
       " 'believed',\n",
       " 'in',\n",
       " 'him',\n",
       " 'when',\n",
       " 'he',\n",
       " 'had',\n",
       " 'been',\n",
       " 'but',\n",
       " 'day',\n",
       " 'in',\n",
       " 'their',\n",
       " 'city.',\n",
       " '',\n",
       " 'hailed',\n",
       " 'him,',\n",
       " 'saying:',\n",
       " '',\n",
       " 'Prophet',\n",
       " 'of',\n",
       " 'God,',\n",
       " 'in',\n",
       " 'quest',\n",
       " 'of',\n",
       " 'uttermost,',\n",
       " 'long',\n",
       " 'have',\n",
       " 'you',\n",
       " 'searched',\n",
       " 'distances',\n",
       " 'for',\n",
       " 'your',\n",
       " 'ship.',\n",
       " '',\n",
       " 'And',\n",
       " 'now',\n",
       " 'your',\n",
       " 'ship',\n",
       " 'has',\n",
       " 'come,',\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat))\n",
    "prophet_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    return [True if i.lower() in word_list else False for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jesus Christ'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_space(a, b):\n",
    "    return  a + ' ' + b\n",
    "concat_space('Jesus', 'Christ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_string = reduce(concat_space, prophet_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will connect to Ironhack's database and retrieve the data from the *pollution* database. Select the *beijing_pollution* table and retrieve its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/beijing_pollution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>19.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>21.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>24.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>27.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0\n",
       "5   6  2010      1    1     5    NaN   -19 -10.0  1017.0   NW  16.10   0   0\n",
       "6   7  2010      1    1     6    NaN   -19  -9.0  1017.0   NW  19.23   0   0\n",
       "7   8  2010      1    1     7    NaN   -19  -9.0  1017.0   NW  21.02   0   0\n",
       "8   9  2010      1    1     8    NaN   -19  -9.0  1017.0   NW  24.15   0   0\n",
       "9  10  2010      1    1     9    NaN   -20  -8.0  1017.0   NW  27.28   0   0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    return x / 24\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_hourly = df[['Iws', 'Is', 'Ir']].apply(hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    return (np.std(x)/(x.count()-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_hourly_sd = df[['Iws', 'Is', 'Ir']].apply(sample_sd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
